"# MediaPipe graph that performs multi-hand tracking with TensorFlow Lite on GPU.\n"
"# Used in the examples in\n"
"# mediapipe/examples/android/src/java/com/mediapipe/apps/handtrackinggpu.\n"
"\n"
"# GPU image. (GpuBuffer)\n"
"input_stream: \"input_video\"\n"
"input_stream: \"image_data\"\n"
"\n"
"# illixr type data\n"
"output_stream: \"illixr_data\"\n"
"# Collection of detected/predicted hands, each represented as a list of\n"
"# landmarks. (std::vector<NormalizedLandmarkList>)\n"
"output_stream: \"hand_landmarks\"\n"
"\n"
"# Generates side packet cotaining max number of hands to detect/track.\n"
"node {\n"
"  calculator: \"ConstantSidePacketCalculator\"\n"
"  output_side_packet: \"PACKET:num_hands\"\n"
"  node_options: {\n"
"    [type.googleapis.com/mediapipe.ConstantSidePacketCalculatorOptions]: {\n"
"      packet { int_value: 2 }\n"
"    }\n"
"  }\n"
"}\n"
"\n"
"# Detects/tracks hand landmarks.\n"
"node {\n"
"  calculator: \"HandLandmarkTrackingGpu\"\n"
"  input_stream: \"IMAGE:input_video\"\n"
"  input_side_packet: \"NUM_HANDS:num_hands\"\n"
"  output_stream: \"LANDMARKS:hand_landmarks\"\n"
"  output_stream: \"HANDEDNESS:handedness\"\n"
"  output_stream: \"PALM_DETECTIONS:palm_detections\"\n"
"  output_stream: \"HAND_ROIS_FROM_LANDMARKS:hand_rects_from_landmarks\"\n"
"  output_stream: \"HAND_ROIS_FROM_PALM_DETECTIONS:hand_rects_from_palm_detections\"\n"
"}\n"
"\n"
"# Subgraph that renders annotations and overlays them on top of the input\n"
"# images (see hand_renderer_gpu.pbtxt).\n"
"node {\n"
"  calculator: \"HandRendererSubgraph\"\n"
"  input_stream: \"IMAGE:input_video\"\n"
"  input_stream: \"IMAGE_DATA:image_data\"\n"
"  input_stream: \"DETECTIONS:palm_detections\"\n"
"  input_stream: \"LANDMARKS:hand_landmarks\"\n"
"  input_stream: \"HANDEDNESS:handedness\"\n"
"  input_stream: \"NORM_RECTS:0:hand_rects_from_palm_detections\"\n"
"  input_stream: \"NORM_RECTS:1:hand_rects_from_landmarks\"\n"
"  output_stream: \"ILLIXR_DATA:illixr_data\"\n"
"}\n"
