
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://illixr.github.io/hand_tracking/v1.0/api/inference__interpreter__delegate__runner_8cc_source/">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.7">
    
    
      
        <title>File inference_interpreter_delegate_runner.cc - ILLIXR Hand Tracking Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/mkd-extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: none; }
    .glightbox-clean .gslide-media {
        -webkit-box-shadow: none;
        box-shadow: none;
    }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#file-inference_interpreter_delegate_runnercc" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      



<header class="md-header md-header--shadow" data-md-component="header" style="background-color: #11284b">
    <nav class="md-header__inner md-grid" aria-label="Header">
        <a href="../.." title="ILLIXR Hand Tracking Documentation" class="md-header__button md-logo" aria-label="ILLIXR Hand Tracking Documentation" data-md-component="logo">
            <img src="../../images/icon.png" alt="logo">
        </a>
        <label class="md-header__button md-icon" for="__drawer">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
        </label>
        <div class="md-header__title" data-md-component="header-title">
            <div class="md-header__ellipsis">
                <div class="md-header__topic">
          <span class="md-ellipsis">
            ILLIXR Hand Tracking Documentation
          </span>
                </div>
                <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              File inference_interpreter_delegate_runner.cc
            
          </span>
                </div>
            </div>
        </div>
        
        
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
        
        
        
        <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
        
        
        
        <label class="md-header__button md-icon" for="__search">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
        
    </nav>
    
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
    <label class="md-nav__title" for="__drawer" style="background-color:var(--md-nav-hdr-color);color:var(--md-nav-hdr-fg-color);">
        <a href="../.." title="ILLIXR Hand Tracking Documentation" class="md-nav__button md-logo" aria-label="ILLIXR Hand Tracking Documentation" data-md-component="logo">
            <img src="../../images/icon.png" alt="logo">
        </a>
        ILLIXR Hand Tracking Documentation
    </label>
    
    <ul class="md-nav__list" data-md-scrollfix style="background-color:var(--md-nav-list-color)">
        
        
        




















<li class="md-nav__item md-nav__item--nested">


    
    
    
    <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
    
    
    
    <div class="md-nav__link md-nav__container" style="color:black;">
        <a href="../.." class="md-nav__link ">
            

<span class="md-ellipsis">
    Latest Documentation
    
  </span>


        </a>
        
        
        <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="0">
            <span class="md-nav__icon md-icon"></span>
        </label>
        
    </div>
    
    <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Latest Documentation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
            
            
            
            
            


















<li class="md-nav__item md-nav__item--nested">


    
    
    
    <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_2" >
    
    
    <label class="md-nav__link" for="__nav_1_2" id="__nav_1_2_label" tabindex="0" style="color:black;">
        

<span class="md-ellipsis">
    API
    
  </span>


        <span class="md-nav__icon md-icon"></span>
    </label>
    
    <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1_2">
            <span class="md-nav__icon md-icon"></span>
            API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
            
            
            






















<li class="md-nav__item md-nav__item--nested">


    
    
    
    <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_2_1" >
    
    
    <label class="md-nav__link" for="__nav_1_2_1" id="__nav_1_2_1_label" tabindex="0" style="color:black;">
        

<span class="md-ellipsis">
    Hand Tracking
    
  </span>


        <span class="md-nav__icon md-icon"></span>
    </label>
    
    <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_1_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1_2_1">
            <span class="md-nav__icon md-icon"></span>
            Hand Tracking
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
            
            
            




<li class="md-nav__item">
    <a href="../classILLIXR_1_1hand__tracking/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    Plugin
    
  </span>


    </a>
</li>


            
            
            
            




<li class="md-nav__item">
    <a href="../classILLIXR_1_1hand__tracking__publisher/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    Publisher
    
  </span>


    </a>
</li>


            
            
            
            


















<li class="md-nav__item md-nav__item--nested">


    
    
    
    <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_2_1_3" >
    
    
    <label class="md-nav__link" for="__nav_1_2_1_3" id="__nav_1_2_1_3_label" tabindex="0" style="color:black;">
        

<span class="md-ellipsis">
    Data Types
    
  </span>


        <span class="md-nav__icon md-icon"></span>
    </label>
    
    <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_1_2_1_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1_2_1_3">
            <span class="md-nav__icon md-icon"></span>
            Data Types
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
            
            
            




<li class="md-nav__item">
    <a href="../structht__illixr__handle__t/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    illixr_handle_t
    
  </span>


    </a>
</li>


            
            
            
            




<li class="md-nav__item">
    <a href="../structmediapipe_1_1ILLIXR_1_1illixr__ht__frame/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    illixr_ht_frame
    
  </span>


    </a>
</li>


            
            
            
            




<li class="md-nav__item">
    <a href="../structILLIXR_1_1pose__image/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    pose_image
    
  </span>


    </a>
</li>


            
            
        </ul>
    </nav>
    
</li>


            
            
            
            




<li class="md-nav__item">
    <a href="../classmediapipe_1_1ILLIXROutputCalculator/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    ILLIXR Calculator
    
  </span>


    </a>
</li>


            
            
            
            


















<li class="md-nav__item md-nav__item--nested">


    
    
    
    <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_2_1_5" >
    
    
    <label class="md-nav__link" for="__nav_1_2_1_5" id="__nav_1_2_1_5_label" tabindex="0" style="color:black;">
        

<span class="md-ellipsis">
    OpenXR
    
  </span>


        <span class="md-nav__icon md-icon"></span>
    </label>
    
    <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_1_2_1_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            OpenXR
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
            
            
            




<li class="md-nav__item">
    <a href="../interface_8h/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    Interface
    
  </span>


    </a>
</li>


            
            
            
            




<li class="md-nav__item">
    <a href="../ixr__openxr_8hpp/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    Func. Implementations
    
  </span>


    </a>
</li>


            
            
            
            
















<li class="md-nav__item md-nav__item--nested">


    
    
    
    <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_2_1_5_3" >
    
    
    <label class="md-nav__link" for="__nav_1_2_1_5_3" id="__nav_1_2_1_5_3_label" tabindex="0" style="color:black;">
        

<span class="md-ellipsis">
    Structs
    
  </span>


        <span class="md-nav__icon md-icon"></span>
    </label>
    
    <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_1_2_1_5_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1_2_1_5_3">
            <span class="md-nav__icon md-icon"></span>
            Structs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
            
            
            




<li class="md-nav__item">
    <a href="../structixr__hand__tracker/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    ixr_hand+tracker
    
  </span>


    </a>
</li>


            
            
            
            




<li class="md-nav__item">
    <a href="../structixr__session/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    ixr_session
    
  </span>


    </a>
</li>


            
            
        </ul>
    </nav>
    
</li>


            
            
        </ul>
    </nav>
    
</li>


            
            
        </ul>
    </nav>
    
</li>


            
            
            
            




<li class="md-nav__item">
    <a href="../classes/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    Classes
    
  </span>


    </a>
</li>


            
            
            
            




<li class="md-nav__item">
    <a href="../namespacemediapipe/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    Namespaces
    
  </span>


    </a>
</li>


            
            
        </ul>
    </nav>
    
</li>


            
            
            
            




<li class="md-nav__item">
    <a href="../../LICENSE/" class="md-nav__link" style="color:black;">
        

<span class="md-ellipsis">
    License
    
  </span>


    </a>
</li>


            
            
        </ul>
    </nav>
    
</li>


        
    </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
    
    
    
    
    
    
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="file-inference_interpreter_delegate_runnercc">File inference_interpreter_delegate_runner.cc</h1>
<p><a href="../files/"><strong>File List</strong></a> <strong>&gt;</strong> <a href="../dir_7de48a4070c80fa3efc18382090478f6/"><strong>calculators</strong></a> <strong>&gt;</strong> <a href="../dir_05267f8398f0597d1993d349e8194fa9/"><strong>tensor</strong></a> <strong>&gt;</strong> <a href="../inference__interpreter__delegate__runner_8cc/"><strong>inference_interpreter_delegate_runner.cc</strong></a></p>
<p><a href="../inference__interpreter__delegate__runner_8cc/">Go to the documentation of this file</a></p>
<div class="language-C++ highlight"><pre><span></span><code><span id="__span-0-1"><span class="c1">// Copyright 2022 The MediaPipe Authors.</span>
</span><span id="__span-0-2"><span class="c1">//</span>
</span><span id="__span-0-3"><span class="c1">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
</span><span id="__span-0-4"><span class="c1">// you may not use this file except in compliance with the License.</span>
</span><span id="__span-0-5"><span class="c1">// You may obtain a copy of the License at</span>
</span><span id="__span-0-6"><span class="c1">//</span>
</span><span id="__span-0-7"><span class="c1">//      http://www.apache.org/licenses/LICENSE-2.0</span>
</span><span id="__span-0-8"><span class="c1">//</span>
</span><span id="__span-0-9"><span class="c1">// Unless required by applicable law or agreed to in writing, software</span>
</span><span id="__span-0-10"><span class="c1">// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
</span><span id="__span-0-11"><span class="c1">// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
</span><span id="__span-0-12"><span class="c1">// See the License for the specific language governing permissions and</span>
</span><span id="__span-0-13"><span class="c1">// limitations under the License.</span>
</span><span id="__span-0-14">
</span><span id="__span-0-15"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/calculators/tensor/inference_interpreter_delegate_runner.h&quot;</span>
</span><span id="__span-0-16">
</span><span id="__span-0-17"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdint&gt;</span>
</span><span id="__span-0-18"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstring&gt;</span>
</span><span id="__span-0-19"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;memory&gt;</span>
</span><span id="__span-0-20"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;utility&gt;</span>
</span><span id="__span-0-21"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
</span><span id="__span-0-22">
</span><span id="__span-0-23"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;absl/status/status.h&quot;</span>
</span><span id="__span-0-24"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;absl/status/statusor.h&quot;</span>
</span><span id="__span-0-25"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/calculators/tensor/inference_feedback_manager.h&quot;</span>
</span><span id="__span-0-26"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/calculators/tensor/inference_io_mapper.h&quot;</span>
</span><span id="__span-0-27"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/calculators/tensor/tensor_span.h&quot;</span>
</span><span id="__span-0-28"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/calculators/tensor/tflite_delegate_ptr.h&quot;</span>
</span><span id="__span-0-29"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/framework/api2/packet.h&quot;</span>
</span><span id="__span-0-30"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/framework/calculator_framework.h&quot;</span>
</span><span id="__span-0-31"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/framework/formats/tensor.h&quot;</span>
</span><span id="__span-0-32"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/framework/mediapipe_profiling.h&quot;</span>
</span><span id="__span-0-33"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/framework/port/ret_check.h&quot;</span>
</span><span id="__span-0-34"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/framework/port/status_macros.h&quot;</span>
</span><span id="__span-0-35"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/util/tflite/tflite_model_loader.h&quot;</span>
</span><span id="__span-0-36"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;tensorflow/lite/c/c_api_types.h&quot;</span>
</span><span id="__span-0-37"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;tensorflow/lite/c/common.h&quot;</span>
</span><span id="__span-0-38"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;tensorflow/lite/interpreter_builder.h&quot;</span>
</span><span id="__span-0-39"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;tensorflow/lite/string_util.h&quot;</span>
</span><span id="__span-0-40"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;mediapipe/util/unused.hpp&quot;</span>
</span><span id="__span-0-41">
</span><span id="__span-0-42"><span class="k">namespace</span><span class="w"> </span><span class="nn">mediapipe</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-43">
</span><span id="__span-0-44"><span class="k">namespace</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-45">
</span><span id="__span-0-46"><span class="k">using</span><span class="w"> </span><span class="n">Interpreter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">::</span><span class="n">tflite</span><span class="o">::</span><span class="n">Interpreter</span><span class="p">;</span>
</span><span id="__span-0-47"><span class="k">using</span><span class="w"> </span><span class="n">InterpreterBuilder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">::</span><span class="n">tflite</span><span class="o">::</span><span class="n">InterpreterBuilder</span><span class="p">;</span>
</span><span id="__span-0-48">
</span><span id="__span-0-49"><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
</span><span id="__span-0-50"><span class="kt">void</span><span class="w"> </span><span class="n">CopyTensorBufferToInterpreter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">input_tensor</span><span class="p">,</span>
</span><span id="__span-0-51"><span class="w">                                   </span><span class="n">Interpreter</span><span class="o">*</span><span class="w"> </span><span class="n">interpreter</span><span class="p">,</span>
</span><span id="__span-0-52"><span class="w">                                   </span><span class="kt">int</span><span class="w"> </span><span class="n">input_tensor_index</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-53"><span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">input_tensor_view</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_tensor</span><span class="p">.</span><span class="n">GetCpuReadView</span><span class="p">();</span>
</span><span id="__span-0-54"><span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">input_tensor_buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input_tensor_view</span><span class="p">.</span><span class="n">buffer</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">();</span>
</span><span id="__span-0-55"><span class="w">  </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">local_tensor_buffer</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-0-56"><span class="w">      </span><span class="n">interpreter</span><span class="o">-&gt;</span><span class="n">typed_input_tensor</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_tensor_index</span><span class="p">);</span>
</span><span id="__span-0-57"><span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">local_tensor_buffer</span><span class="p">,</span><span class="w"> </span><span class="n">input_tensor_buffer</span><span class="p">,</span><span class="w"> </span><span class="n">input_tensor</span><span class="p">.</span><span class="n">bytes</span><span class="p">());</span>
</span><span id="__span-0-58"><span class="p">}</span>
</span><span id="__span-0-59">
</span><span id="__span-0-60"><span class="k">template</span><span class="w"> </span><span class="o">&lt;&gt;</span>
</span><span id="__span-0-61"><span class="kt">void</span><span class="w"> </span><span class="n">CopyTensorBufferToInterpreter</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">input_tensor</span><span class="p">,</span>
</span><span id="__span-0-62"><span class="w">                                         </span><span class="n">Interpreter</span><span class="o">*</span><span class="w"> </span><span class="n">interpreter</span><span class="p">,</span>
</span><span id="__span-0-63"><span class="w">                                         </span><span class="kt">int</span><span class="w"> </span><span class="n">input_tensor_index</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-64"><span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">input_tensor_buffer</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-0-65"><span class="w">      </span><span class="n">input_tensor</span><span class="p">.</span><span class="n">GetCpuReadView</span><span class="p">().</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span><span class="p">();</span>
</span><span id="__span-0-66"><span class="w">  </span><span class="n">tflite</span><span class="o">::</span><span class="n">DynamicBuffer</span><span class="w"> </span><span class="n">dynamic_buffer</span><span class="p">;</span>
</span><span id="__span-0-67"><span class="w">  </span><span class="n">dynamic_buffer</span><span class="p">.</span><span class="n">AddString</span><span class="p">(</span><span class="n">input_tensor_buffer</span><span class="p">,</span>
</span><span id="__span-0-68"><span class="w">                           </span><span class="n">input_tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">().</span><span class="n">num_elements</span><span class="p">());</span>
</span><span id="__span-0-69"><span class="w">  </span><span class="n">dynamic_buffer</span><span class="p">.</span><span class="n">WriteToTensorAsVector</span><span class="p">(</span>
</span><span id="__span-0-70"><span class="w">      </span><span class="n">interpreter</span><span class="o">-&gt;</span><span class="n">tensor</span><span class="p">(</span><span class="n">interpreter</span><span class="o">-&gt;</span><span class="n">inputs</span><span class="p">()[</span><span class="n">input_tensor_index</span><span class="p">]));</span>
</span><span id="__span-0-71"><span class="p">}</span>
</span><span id="__span-0-72">
</span><span id="__span-0-73"><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
</span><span id="__span-0-74"><span class="kt">void</span><span class="w"> </span><span class="n">CopyTensorBufferFromInterpreter</span><span class="p">(</span><span class="n">Interpreter</span><span class="o">*</span><span class="w"> </span><span class="n">interpreter</span><span class="p">,</span>
</span><span id="__span-0-75"><span class="w">                                     </span><span class="kt">int</span><span class="w"> </span><span class="n">output_tensor_index</span><span class="p">,</span>
</span><span id="__span-0-76"><span class="w">                                     </span><span class="n">Tensor</span><span class="o">*</span><span class="w"> </span><span class="n">output_tensor</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-77"><span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">output_tensor_view</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output_tensor</span><span class="o">-&gt;</span><span class="n">GetCpuWriteView</span><span class="p">();</span>
</span><span id="__span-0-78"><span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">output_tensor_buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output_tensor_view</span><span class="p">.</span><span class="n">buffer</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">();</span>
</span><span id="__span-0-79"><span class="w">  </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">local_tensor_buffer</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-0-80"><span class="w">      </span><span class="n">interpreter</span><span class="o">-&gt;</span><span class="n">typed_output_tensor</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">output_tensor_index</span><span class="p">);</span>
</span><span id="__span-0-81"><span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">memcpy</span><span class="p">(</span><span class="n">output_tensor_buffer</span><span class="p">,</span><span class="w"> </span><span class="n">local_tensor_buffer</span><span class="p">,</span>
</span><span id="__span-0-82"><span class="w">              </span><span class="n">output_tensor</span><span class="o">-&gt;</span><span class="n">bytes</span><span class="p">());</span>
</span><span id="__span-0-83"><span class="p">}</span>
</span><span id="__span-0-84">
</span><span id="__span-0-85"><span class="p">}</span><span class="w">  </span><span class="c1">// namespace</span>
</span><span id="__span-0-86">
</span><span id="__span-0-87"><span class="k">class</span><span class="w"> </span><span class="nc">InferenceInterpreterDelegateRunner</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">InferenceRunner</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-88"><span class="w"> </span><span class="k">public</span><span class="o">:</span>
</span><span id="__span-0-89"><span class="w">  </span><span class="n">InferenceInterpreterDelegateRunner</span><span class="p">(</span>
</span><span id="__span-0-90"><span class="w">      </span><span class="n">api2</span><span class="o">::</span><span class="n">Packet</span><span class="o">&lt;</span><span class="n">TfLiteModelPtr</span><span class="o">&gt;</span><span class="w"> </span><span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-91"><span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">Interpreter</span><span class="o">&gt;</span><span class="w"> </span><span class="n">interpreter</span><span class="p">,</span><span class="w"> </span><span class="n">TfLiteDelegatePtr</span><span class="w"> </span><span class="n">delegate</span><span class="p">,</span>
</span><span id="__span-0-92"><span class="w">      </span><span class="n">InputOutputTensorNames</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">input_output_tensor_names</span><span class="p">,</span>
</span><span id="__span-0-93"><span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">InferenceFeedbackManager</span><span class="o">&gt;</span><span class="w"> </span><span class="n">feedback_manager</span><span class="p">)</span>
</span><span id="__span-0-94"><span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">model_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">model</span><span class="p">)),</span>
</span><span id="__span-0-95"><span class="w">        </span><span class="n">interpreter_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">interpreter</span><span class="p">)),</span>
</span><span id="__span-0-96"><span class="w">        </span><span class="n">delegate_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">delegate</span><span class="p">)),</span>
</span><span id="__span-0-97"><span class="w">        </span><span class="n">input_output_tensor_names_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">input_output_tensor_names</span><span class="p">)),</span>
</span><span id="__span-0-98"><span class="w">        </span><span class="n">feedback_manager_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">feedback_manager</span><span class="p">))</span><span class="w"> </span><span class="p">{}</span>
</span><span id="__span-0-99">
</span><span id="__span-0-100"><span class="w">  </span><span class="n">absl</span><span class="o">::</span><span class="n">StatusOr</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">Run</span><span class="p">(</span>
</span><span id="__span-0-101"><span class="w">      </span><span class="n">CalculatorContext</span><span class="o">*</span><span class="w"> </span><span class="n">cc</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">TensorSpan</span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor_span</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>
</span><span id="__span-0-102">
</span><span id="__span-0-103"><span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">InputOutputTensorNames</span><span class="o">&amp;</span><span class="w"> </span><span class="nf">GetInputOutputTensorNames</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-104"><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">input_output_tensor_names_</span><span class="p">;</span>
</span><span id="__span-0-105"><span class="w">  </span><span class="p">}</span>
</span><span id="__span-0-106">
</span><span id="__span-0-107"><span class="w"> </span><span class="k">private</span><span class="o">:</span>
</span><span id="__span-0-108"><span class="w">  </span><span class="n">api2</span><span class="o">::</span><span class="n">Packet</span><span class="o">&lt;</span><span class="n">TfLiteModelPtr</span><span class="o">&gt;</span><span class="w"> </span><span class="n">model_</span><span class="p">;</span>
</span><span id="__span-0-109"><span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">Interpreter</span><span class="o">&gt;</span><span class="w"> </span><span class="n">interpreter_</span><span class="p">;</span>
</span><span id="__span-0-110"><span class="w">  </span><span class="n">TfLiteDelegatePtr</span><span class="w"> </span><span class="n">delegate_</span><span class="p">;</span>
</span><span id="__span-0-111"><span class="w">  </span><span class="n">InputOutputTensorNames</span><span class="w"> </span><span class="n">input_output_tensor_names_</span><span class="p">;</span>
</span><span id="__span-0-112"><span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">InferenceFeedbackManager</span><span class="o">&gt;</span><span class="w"> </span><span class="n">feedback_manager_</span><span class="p">;</span>
</span><span id="__span-0-113"><span class="p">};</span>
</span><span id="__span-0-114">
</span><span id="__span-0-115"><span class="n">absl</span><span class="o">::</span><span class="n">StatusOr</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">InferenceInterpreterDelegateRunner</span><span class="o">::</span><span class="n">Run</span><span class="p">(</span>
</span><span id="__span-0-116"><span class="w">    </span><span class="n">CalculatorContext</span><span class="o">*</span><span class="w"> </span><span class="n">cc</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">TensorSpan</span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor_span</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-117"><span class="w">    </span><span class="n">UNUSED</span><span class="p">(</span><span class="n">cc</span><span class="p">);</span>
</span><span id="__span-0-118"><span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">num_feedback_tensors</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-0-119"><span class="w">      </span><span class="n">feedback_manager_</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">feedback_manager_</span><span class="o">-&gt;</span><span class="n">GetNumberOfFeedbackTensors</span><span class="p">()</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</span><span id="__span-0-120">
</span><span id="__span-0-121"><span class="w">  </span><span class="n">RET_CHECK_EQ</span><span class="p">((</span><span class="kt">size_t</span><span class="p">)(</span><span class="n">tensor_span</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">num_feedback_tensors</span><span class="p">),</span>
</span><span id="__span-0-122"><span class="w">               </span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">inputs</span><span class="p">().</span><span class="n">size</span><span class="p">());</span>
</span><span id="__span-0-123">
</span><span id="__span-0-124"><span class="w">  </span><span class="c1">// If the input tensors have dynamic shape, then the tensors need to be</span>
</span><span id="__span-0-125"><span class="w">  </span><span class="c1">// resized and reallocated before we can copy the tensor values.</span>
</span><span id="__span-0-126"><span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">resized_tensor_shapes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
</span><span id="__span-0-127"><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">tensor_span</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-128"><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">input_model_index</span><span class="p">;</span>
</span><span id="__span-0-129"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">feedback_manager_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-130"><span class="w">      </span><span class="c1">// Feedback tensors are stripped from the InferenceRunner input. Calling</span>
</span><span id="__span-0-131"><span class="w">      </span><span class="c1">// MapInputTensorToModelIndex assigns the input tensors to the correct</span>
</span><span id="__span-0-132"><span class="w">      </span><span class="c1">// model index.</span>
</span><span id="__span-0-133"><span class="w">      </span><span class="n">MP_ASSIGN_OR_RETURN</span><span class="p">(</span><span class="n">input_model_index</span><span class="p">,</span>
</span><span id="__span-0-134"><span class="w">                          </span><span class="n">feedback_manager_</span><span class="o">-&gt;</span><span class="n">MapInputTensorToModelIndex</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
</span><span id="__span-0-135"><span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-136"><span class="w">      </span><span class="n">input_model_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
</span><span id="__span-0-137"><span class="w">    </span><span class="p">}</span>
</span><span id="__span-0-138"><span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">input_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tensor_span</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-0-139"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">input_tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">().</span><span class="n">is_dynamic</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-140"><span class="w">      </span><span class="k">const</span><span class="w"> </span><span class="n">TfLiteTensor</span><span class="o">*</span><span class="w"> </span><span class="n">interpreter_tensor</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-0-141"><span class="w">          </span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">tensor</span><span class="p">(</span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">inputs</span><span class="p">()[</span><span class="n">input_model_index</span><span class="p">]);</span>
</span><span id="__span-0-142"><span class="w">      </span><span class="c1">// TODO: Can avoid copying even these &lt;= 4 values in the future.</span>
</span><span id="__span-0-143"><span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">interpreter_dims</span><span class="p">{</span>
</span><span id="__span-0-144"><span class="w">          </span><span class="n">interpreter_tensor</span><span class="o">-&gt;</span><span class="n">dims</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">,</span>
</span><span id="__span-0-145"><span class="w">          </span><span class="n">interpreter_tensor</span><span class="o">-&gt;</span><span class="n">dims</span><span class="o">-&gt;</span><span class="n">data</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">interpreter_tensor</span><span class="o">-&gt;</span><span class="n">dims</span><span class="o">-&gt;</span><span class="n">size</span><span class="p">};</span>
</span><span id="__span-0-146"><span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">interpreter_dims</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">input_tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">().</span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-147"><span class="w">        </span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">ResizeInputTensorStrict</span><span class="p">(</span><span class="n">input_model_index</span><span class="p">,</span>
</span><span id="__span-0-148"><span class="w">                                              </span><span class="n">input_tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">().</span><span class="n">dims</span><span class="p">);</span>
</span><span id="__span-0-149"><span class="w">        </span><span class="n">resized_tensor_shapes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
</span><span id="__span-0-150"><span class="w">      </span><span class="p">}</span>
</span><span id="__span-0-151"><span class="w">    </span><span class="p">}</span>
</span><span id="__span-0-152"><span class="w">  </span><span class="p">}</span>
</span><span id="__span-0-153"><span class="w">  </span><span class="c1">// Reallocation is needed for memory sanity.</span>
</span><span id="__span-0-154"><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">resized_tensor_shapes</span><span class="p">)</span><span class="w"> </span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">AllocateTensors</span><span class="p">();</span>
</span><span id="__span-0-155">
</span><span id="__span-0-156"><span class="w">  </span><span class="c1">// TODO: Replace this using the util function in</span>
</span><span id="__span-0-157"><span class="w">  </span><span class="c1">// inference_calculator_utils.</span>
</span><span id="__span-0-158"><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">tensor_span</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-159"><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">input_model_index</span><span class="p">;</span>
</span><span id="__span-0-160"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">feedback_manager_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-161"><span class="w">      </span><span class="c1">// Feedback tensors are stripped from the InferenceRunner input. Calling</span>
</span><span id="__span-0-162"><span class="w">      </span><span class="c1">// MapInputTensorToModelIndex assigns the input tensors to the correct</span>
</span><span id="__span-0-163"><span class="w">      </span><span class="c1">// model index.</span>
</span><span id="__span-0-164"><span class="w">      </span><span class="n">MP_ASSIGN_OR_RETURN</span><span class="p">(</span><span class="n">input_model_index</span><span class="p">,</span>
</span><span id="__span-0-165"><span class="w">                          </span><span class="n">feedback_manager_</span><span class="o">-&gt;</span><span class="n">MapInputTensorToModelIndex</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
</span><span id="__span-0-166"><span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-167"><span class="w">      </span><span class="n">input_model_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
</span><span id="__span-0-168"><span class="w">    </span><span class="p">}</span>
</span><span id="__span-0-169"><span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">TfLiteType</span><span class="w"> </span><span class="n">input_tensor_type</span><span class="w"> </span><span class="o">=</span>
</span><span id="__span-0-170"><span class="w">        </span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">tensor</span><span class="p">(</span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">inputs</span><span class="p">()[</span><span class="n">input_model_index</span><span class="p">])</span><span class="o">-&gt;</span><span class="n">type</span><span class="p">;</span>
</span><span id="__span-0-171"><span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">input_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tensor_span</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span><span id="__span-0-172"><span class="w">    </span><span class="k">switch</span><span class="w"> </span><span class="p">(</span><span class="n">input_tensor_type</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-173"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteFloat16</span><span class="p">:</span>
</span><span id="__span-0-174"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteFloat32</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-175"><span class="w">        </span><span class="n">CopyTensorBufferToInterpreter</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span>
</span><span id="__span-0-176"><span class="w">                                             </span><span class="n">input_model_index</span><span class="p">);</span>
</span><span id="__span-0-177"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-178"><span class="w">      </span><span class="p">}</span>
</span><span id="__span-0-179"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteUInt8</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-180"><span class="w">        </span><span class="n">CopyTensorBufferToInterpreter</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span>
</span><span id="__span-0-181"><span class="w">                                               </span><span class="n">input_model_index</span><span class="p">);</span>
</span><span id="__span-0-182"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-183"><span class="w">      </span><span class="p">}</span>
</span><span id="__span-0-184"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteInt8</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-185"><span class="w">        </span><span class="n">CopyTensorBufferToInterpreter</span><span class="o">&lt;</span><span class="kt">int8_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span>
</span><span id="__span-0-186"><span class="w">                                              </span><span class="n">input_model_index</span><span class="p">);</span>
</span><span id="__span-0-187"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-188"><span class="w">      </span><span class="p">}</span>
</span><span id="__span-0-189"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteInt32</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-190"><span class="w">        </span><span class="n">CopyTensorBufferToInterpreter</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span>
</span><span id="__span-0-191"><span class="w">                                               </span><span class="n">input_model_index</span><span class="p">);</span>
</span><span id="__span-0-192"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-193"><span class="w">      </span><span class="p">}</span>
</span><span id="__span-0-194"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteString</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-195"><span class="w">        </span><span class="n">CopyTensorBufferToInterpreter</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span>
</span><span id="__span-0-196"><span class="w">                                            </span><span class="n">input_model_index</span><span class="p">);</span>
</span><span id="__span-0-197"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-198"><span class="w">      </span><span class="p">}</span>
</span><span id="__span-0-199"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteBool</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-200"><span class="w">        </span><span class="n">CopyTensorBufferToInterpreter</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span><span class="w"> </span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span>
</span><span id="__span-0-201"><span class="w">                                            </span><span class="n">input_model_index</span><span class="p">);</span>
</span><span id="__span-0-202"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-203"><span class="w">      </span><span class="p">}</span>
</span><span id="__span-0-204"><span class="w">      </span><span class="k">default</span><span class="o">:</span>
</span><span id="__span-0-205"><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">absl</span><span class="o">::</span><span class="n">InvalidArgumentError</span><span class="p">(</span>
</span><span id="__span-0-206"><span class="w">            </span><span class="n">absl</span><span class="o">::</span><span class="n">StrCat</span><span class="p">(</span><span class="s">&quot;Unsupported input tensor type:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">input_tensor_type</span><span class="p">));</span>
</span><span id="__span-0-207"><span class="w">    </span><span class="p">}</span>
</span><span id="__span-0-208"><span class="w">  </span><span class="p">}</span>
</span><span id="__span-0-209">
</span><span id="__span-0-210"><span class="w">  </span><span class="c1">// Run inference.</span>
</span><span id="__span-0-211"><span class="w">  </span><span class="p">{</span>
</span><span id="__span-0-212"><span class="w">    </span><span class="n">MEDIAPIPE_PROFILING</span><span class="p">(</span><span class="n">CPU_TASK_INVOKE</span><span class="p">,</span><span class="w"> </span><span class="n">cc</span><span class="p">)</span>
</span><span id="__span-0-213"><span class="w">    </span><span class="n">RET_CHECK_EQ</span><span class="p">(</span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">Invoke</span><span class="p">(),</span><span class="w"> </span><span class="n">kTfLiteOk</span><span class="p">);</span>
</span><span id="__span-0-214"><span class="w">  </span><span class="p">}</span>
</span><span id="__span-0-215"><span class="w">  </span><span class="c1">// Output result tensors (CPU).</span>
</span><span id="__span-0-216"><span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor_indexes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">outputs</span><span class="p">();</span>
</span><span id="__span-0-217"><span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_tensors</span><span class="p">;</span>
</span><span id="__span-0-218"><span class="w">  </span><span class="n">output_tensors</span><span class="p">.</span><span class="n">reserve</span><span class="p">(</span><span class="n">tensor_indexes</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">num_feedback_tensors</span><span class="p">);</span>
</span><span id="__span-0-219"><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="n">tensor_indexes</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-220"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">feedback_manager_</span><span class="w"> </span><span class="o">&amp;&amp;</span>
</span><span id="__span-0-221"><span class="w">        </span><span class="n">feedback_manager_</span><span class="o">-&gt;</span><span class="n">IsFeedbackOutputTensorAtIndex</span><span class="p">(</span><span class="n">i</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-222"><span class="w">      </span><span class="c1">// Exclude feedback tensors from InferenceRunner output.</span>
</span><span id="__span-0-223"><span class="w">      </span><span class="k">continue</span><span class="p">;</span>
</span><span id="__span-0-224"><span class="w">    </span><span class="p">}</span>
</span><span id="__span-0-225"><span class="w">    </span><span class="n">TfLiteTensor</span><span class="o">*</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">interpreter_</span><span class="o">-&gt;</span><span class="n">tensor</span><span class="p">(</span><span class="n">tensor_indexes</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span><span id="__span-0-226"><span class="w">    </span><span class="n">Tensor</span><span class="o">::</span><span class="n">Shape</span><span class="w"> </span><span class="n">shape</span><span class="p">{</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">{</span>
</span><span id="__span-0-227"><span class="w">        </span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">dims</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">dims</span><span class="o">-&gt;</span><span class="n">data</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">dims</span><span class="o">-&gt;</span><span class="n">size</span><span class="p">}};</span>
</span><span id="__span-0-228"><span class="w">    </span><span class="k">switch</span><span class="w"> </span><span class="p">(</span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">type</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-229"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteFloat16</span><span class="p">:</span>
</span><span id="__span-0-230"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteFloat32</span><span class="p">:</span>
</span><span id="__span-0-231"><span class="w">        </span><span class="n">output_tensors</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">Tensor</span><span class="o">::</span><span class="n">ElementType</span><span class="o">::</span><span class="n">kFloat32</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="p">);</span>
</span><span id="__span-0-232"><span class="w">        </span><span class="n">CopyTensorBufferFromInterpreter</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span><span class="w"> </span><span class="n">i</span><span class="p">,</span>
</span><span id="__span-0-233"><span class="w">                                               </span><span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">.</span><span class="n">back</span><span class="p">());</span>
</span><span id="__span-0-234"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-235"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteUInt8</span><span class="p">:</span>
</span><span id="__span-0-236"><span class="w">        </span><span class="n">output_tensors</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span>
</span><span id="__span-0-237"><span class="w">            </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ElementType</span><span class="o">::</span><span class="n">kUInt8</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="p">,</span>
</span><span id="__span-0-238"><span class="w">            </span><span class="n">Tensor</span><span class="o">::</span><span class="n">QuantizationParameters</span><span class="p">{</span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">params</span><span class="p">.</span><span class="n">scale</span><span class="p">,</span>
</span><span id="__span-0-239"><span class="w">                                           </span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">params</span><span class="p">.</span><span class="n">zero_point</span><span class="p">});</span>
</span><span id="__span-0-240"><span class="w">        </span><span class="n">CopyTensorBufferFromInterpreter</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span><span class="w"> </span><span class="n">i</span><span class="p">,</span>
</span><span id="__span-0-241"><span class="w">                                                 </span><span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">.</span><span class="n">back</span><span class="p">());</span>
</span><span id="__span-0-242"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-243"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteInt8</span><span class="p">:</span>
</span><span id="__span-0-244"><span class="w">        </span><span class="n">output_tensors</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span>
</span><span id="__span-0-245"><span class="w">            </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ElementType</span><span class="o">::</span><span class="n">kInt8</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="p">,</span>
</span><span id="__span-0-246"><span class="w">            </span><span class="n">Tensor</span><span class="o">::</span><span class="n">QuantizationParameters</span><span class="p">{</span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">params</span><span class="p">.</span><span class="n">scale</span><span class="p">,</span>
</span><span id="__span-0-247"><span class="w">                                           </span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">params</span><span class="p">.</span><span class="n">zero_point</span><span class="p">});</span>
</span><span id="__span-0-248"><span class="w">        </span><span class="n">CopyTensorBufferFromInterpreter</span><span class="o">&lt;</span><span class="kt">int8_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span><span class="w"> </span><span class="n">i</span><span class="p">,</span>
</span><span id="__span-0-249"><span class="w">                                                </span><span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">.</span><span class="n">back</span><span class="p">());</span>
</span><span id="__span-0-250"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-251"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteInt32</span><span class="p">:</span>
</span><span id="__span-0-252"><span class="w">        </span><span class="n">output_tensors</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">Tensor</span><span class="o">::</span><span class="n">ElementType</span><span class="o">::</span><span class="n">kInt32</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="p">);</span>
</span><span id="__span-0-253"><span class="w">        </span><span class="n">CopyTensorBufferFromInterpreter</span><span class="o">&lt;</span><span class="kt">int32_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span><span class="w"> </span><span class="n">i</span><span class="p">,</span>
</span><span id="__span-0-254"><span class="w">                                                 </span><span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">.</span><span class="n">back</span><span class="p">());</span>
</span><span id="__span-0-255"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-256"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteBool</span><span class="p">:</span>
</span><span id="__span-0-257"><span class="w">        </span><span class="n">output_tensors</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">Tensor</span><span class="o">::</span><span class="n">ElementType</span><span class="o">::</span><span class="n">kBool</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="p">,</span>
</span><span id="__span-0-258"><span class="w">                                    </span><span class="n">Tensor</span><span class="o">::</span><span class="n">QuantizationParameters</span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">});</span>
</span><span id="__span-0-259"><span class="w">        </span><span class="n">CopyTensorBufferFromInterpreter</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="p">(</span><span class="n">interpreter_</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span><span class="w"> </span><span class="n">i</span><span class="p">,</span>
</span><span id="__span-0-260"><span class="w">                                              </span><span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">.</span><span class="n">back</span><span class="p">());</span>
</span><span id="__span-0-261"><span class="w">        </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-262"><span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">TfLiteType</span><span class="o">::</span><span class="no">kTfLiteString</span><span class="p">:</span>
</span><span id="__span-0-263"><span class="w">        </span><span class="c1">// No current use-case for copying TfLiteTensors with string type to</span>
</span><span id="__span-0-264"><span class="w">        </span><span class="c1">// MediaPipe Tensors.</span>
</span><span id="__span-0-265"><span class="w">      </span><span class="k">default</span><span class="o">:</span>
</span><span id="__span-0-266"><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">absl</span><span class="o">::</span><span class="n">InvalidArgumentError</span><span class="p">(</span>
</span><span id="__span-0-267"><span class="w">            </span><span class="n">absl</span><span class="o">::</span><span class="n">StrCat</span><span class="p">(</span><span class="s">&quot;Unsupported output tensor type:&quot;</span><span class="p">,</span>
</span><span id="__span-0-268"><span class="w">                         </span><span class="n">TfLiteTypeGetName</span><span class="p">(</span><span class="n">tensor</span><span class="o">-&gt;</span><span class="n">type</span><span class="p">)));</span>
</span><span id="__span-0-269"><span class="w">    </span><span class="p">}</span>
</span><span id="__span-0-270"><span class="w">  </span><span class="p">}</span>
</span><span id="__span-0-271"><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">feedback_manager_</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-272"><span class="w">    </span><span class="n">feedback_manager_</span><span class="o">-&gt;</span><span class="n">SwapFeedbackTensors</span><span class="p">();</span>
</span><span id="__span-0-273"><span class="w">  </span><span class="p">}</span>
</span><span id="__span-0-274"><span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">output_tensors</span><span class="p">;</span>
</span><span id="__span-0-275"><span class="p">}</span>
</span><span id="__span-0-276">
</span><span id="__span-0-277"><span class="n">absl</span><span class="o">::</span><span class="n">StatusOr</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">InferenceRunner</span><span class="o">&gt;&gt;</span>
</span><span id="__span-0-278"><span class="n">CreateInferenceInterpreterDelegateRunner</span><span class="p">(</span>
</span><span id="__span-0-279"><span class="w">    </span><span class="n">api2</span><span class="o">::</span><span class="n">Packet</span><span class="o">&lt;</span><span class="n">TfLiteModelPtr</span><span class="o">&gt;</span><span class="w"> </span><span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-280"><span class="w">    </span><span class="n">api2</span><span class="o">::</span><span class="n">Packet</span><span class="o">&lt;</span><span class="n">tflite</span><span class="o">::</span><span class="n">OpResolver</span><span class="o">&gt;</span><span class="w"> </span><span class="n">op_resolver</span><span class="p">,</span><span class="w"> </span><span class="n">TfLiteDelegatePtr</span><span class="w"> </span><span class="n">delegate</span><span class="p">,</span>
</span><span id="__span-0-281"><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">interpreter_num_threads</span><span class="p">,</span>
</span><span id="__span-0-282"><span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">mediapipe</span><span class="o">::</span><span class="n">InferenceCalculatorOptions</span><span class="o">::</span><span class="n">InputOutputConfig</span><span class="o">*</span>
</span><span id="__span-0-283"><span class="w">        </span><span class="n">input_output_config</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-284"><span class="w">  </span><span class="n">InterpreterBuilder</span><span class="w"> </span><span class="nf">interpreter_builder</span><span class="p">(</span><span class="o">*</span><span class="n">model</span><span class="p">.</span><span class="n">Get</span><span class="p">(),</span><span class="w"> </span><span class="n">op_resolver</span><span class="p">.</span><span class="n">Get</span><span class="p">());</span>
</span><span id="__span-0-285"><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">delegate</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-286"><span class="w">    </span><span class="n">interpreter_builder</span><span class="p">.</span><span class="n">AddDelegate</span><span class="p">(</span><span class="n">delegate</span><span class="p">.</span><span class="n">get</span><span class="p">());</span>
</span><span id="__span-0-287"><span class="w">  </span><span class="p">}</span>
</span><span id="__span-0-288"><span class="cp">#if defined(__EMSCRIPTEN__)</span>
</span><span id="__span-0-289"><span class="w">  </span><span class="n">interpreter_builder</span><span class="p">.</span><span class="n">SetNumThreads</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-0-290"><span class="cp">#else</span>
</span><span id="__span-0-291"><span class="w">  </span><span class="n">interpreter_builder</span><span class="p">.</span><span class="n">SetNumThreads</span><span class="p">(</span><span class="n">interpreter_num_threads</span><span class="p">);</span>
</span><span id="__span-0-292"><span class="cp">#endif  </span><span class="c1">// __EMSCRIPTEN__</span>
</span><span id="__span-0-293"><span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">Interpreter</span><span class="o">&gt;</span><span class="w"> </span><span class="n">interpreter</span><span class="p">;</span>
</span><span id="__span-0-294"><span class="w">  </span><span class="n">RET_CHECK_EQ</span><span class="p">(</span><span class="n">interpreter_builder</span><span class="p">(</span><span class="o">&amp;</span><span class="n">interpreter</span><span class="p">),</span><span class="w"> </span><span class="n">kTfLiteOk</span><span class="p">);</span>
</span><span id="__span-0-295"><span class="w">  </span><span class="n">RET_CHECK</span><span class="p">(</span><span class="n">interpreter</span><span class="p">);</span>
</span><span id="__span-0-296"><span class="w">  </span><span class="n">RET_CHECK_EQ</span><span class="p">(</span><span class="n">interpreter</span><span class="o">-&gt;</span><span class="n">AllocateTensors</span><span class="p">(),</span><span class="w"> </span><span class="n">kTfLiteOk</span><span class="p">);</span>
</span><span id="__span-0-297"><span class="w">  </span><span class="n">MP_ASSIGN_OR_RETURN</span><span class="p">(</span>
</span><span id="__span-0-298"><span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">input_output_tensor_names</span><span class="p">,</span>
</span><span id="__span-0-299"><span class="w">      </span><span class="n">InferenceIoMapper</span><span class="o">::</span><span class="n">GetInputOutputTensorNamesFromInterpreter</span><span class="p">(</span>
</span><span id="__span-0-300"><span class="w">          </span><span class="o">*</span><span class="n">interpreter</span><span class="p">));</span>
</span><span id="__span-0-301"><span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">InferenceFeedbackManager</span><span class="o">&gt;</span><span class="w"> </span><span class="n">inference_feedback_manager</span><span class="p">;</span>
</span><span id="__span-0-302"><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">input_output_config</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-0-303"><span class="w">    </span><span class="c1">// Create inference_feedback_manager if input_output_config is available.</span>
</span><span id="__span-0-304"><span class="w">    </span><span class="n">inference_feedback_manager</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_unique</span><span class="o">&lt;</span><span class="n">InferenceFeedbackManager</span><span class="o">&gt;</span><span class="p">();</span>
</span><span id="__span-0-305"><span class="w">    </span><span class="n">MP_RETURN_IF_ERROR</span><span class="p">(</span><span class="n">inference_feedback_manager</span><span class="o">-&gt;</span><span class="n">Init</span><span class="p">(</span>
</span><span id="__span-0-306"><span class="w">        </span><span class="o">*</span><span class="n">input_output_config</span><span class="p">,</span><span class="w"> </span><span class="n">input_output_tensor_names</span><span class="p">,</span><span class="w"> </span><span class="n">interpreter</span><span class="p">.</span><span class="n">get</span><span class="p">()));</span>
</span><span id="__span-0-307"><span class="w">  </span><span class="p">}</span>
</span><span id="__span-0-308"><span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_unique</span><span class="o">&lt;</span><span class="n">InferenceInterpreterDelegateRunner</span><span class="o">&gt;</span><span class="p">(</span>
</span><span id="__span-0-309"><span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">model</span><span class="p">),</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">interpreter</span><span class="p">),</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">delegate</span><span class="p">),</span>
</span><span id="__span-0-310"><span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">input_output_tensor_names</span><span class="p">),</span>
</span><span id="__span-0-311"><span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">inference_feedback_manager</span><span class="p">));</span>
</span><span id="__span-0-312"><span class="p">}</span>
</span><span id="__span-0-313">
</span><span id="__span-0-314"><span class="p">}</span><span class="w">  </span><span class="c1">// namespace mediapipe</span>
</span></code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["search.suggest", "content.code.annotate", "content.footnote.tooltips", "navigation.indexes"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../js/jquery.min.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": false, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "zoom"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>